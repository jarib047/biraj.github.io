---
title: "Fine-Tuning Small Embeddings for Elevated Performance"
collection: publications
permalink: research/#
excerpt: 'An incomplete BERT model pretrained on Nepali language was fine-tuned using previously unseen data to generate elevated word embeddings. The generated word embeddings were further used in some intrinsic and extrinsic tasks. Performance of the enhanced embedding was compared with that of the pre-trained model and a complete BERT model.'
date: 2022-09-01
venue: arXiv preprint
paperurl: 'https://arxiv.org/abs/2411.18099'
citation: 
---
